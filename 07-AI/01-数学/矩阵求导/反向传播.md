---
创建时间: 2025-07-22 18:51
tags: 
---
好的，我们来详细分解这个推导过程。这个过程看起来很复杂，但它本质上是**链式法则**在矩阵和向量上的一种系统性应用。这个方法叫做**矩阵微分**，它使用全微分（$dl$）和迹（trace, $\operatorname{tr}$）来避免直接处理复杂的四维张量（即矩阵对矩阵的导数）。

我们一步一步来看。
### 核心思想
1.  **目标**: 求标量损失函数 $l$ 对矩阵 $W_1$ 和 $W_2$ 的梯度（偏导数） $\dfrac{\partial l}{\partial W_1}$ 和 $\dfrac{\partial l}{\partial W_2}$。
2.  **方法**: 使用链式法则。从后往前，一步步求梯度。
3.  **工具**:
    * **全微分 (Differential)**: 任何变量 $X$ 的微小变化记为 $dX$。
    * **链式法则的微分形式**: 如果 $l$ 是 $A$ 的函数，$A$ 又是 $B$ 的函数，那么 $l$ 的变化 $dl$ 可以通过 $A$ 的变化 $dA$ 来表示，而 $dA$ 又可以通过 $B$ 的变化 $dB$ 来表示。
    * **迹技巧 (Trace Trick)**: 这是关键。对于一个标量 $l$，有 $l = \operatorname{tr}(l)$。我们的核心公式是：
        $$
        dl = \operatorname{tr}\left( \left(\dfrac{\partial l}{\partial X}\right)^T dX \right)
        $$
        这个公式的美妙之处在于，如果我们能通过一系列变换，将 $dl$ 的表达式整理成 $\operatorname{tr}(C^T dX)$ 的形式，那么我们就可以直接认定 $C = \dfrac{\partial l}{\partial X}$。这就是我们整个推导过程的目标。

### 变量和它们的关系（前向传播）

为了清晰，我们再梳理一遍计算流程：
1.  $\boldsymbol{a}_1 = W_1 \boldsymbol{x}$  （第一层的线性部分）
2.  $\boldsymbol{h}_1 = \sigma(\boldsymbol{a}_1)$ （第一层的激活，Sigmoid）
3.  $\boldsymbol{a}_2 = W_2 \boldsymbol{h}_1$ （第二层的线性部分）
4.  $\hat{\boldsymbol{y}} = \operatorname{softmax}(\boldsymbol{a}_2)$ （第二层的激活，Softmax）
5.  $l = -\boldsymbol{y}^T \log(\hat{\boldsymbol{y}})$ （交叉熵损失）

现在我们开始反向传播求导。

---

### **第一步：求 $\dfrac{\partial l}{\partial W_2}$ 和 $\dfrac{\partial l}{\partial \boldsymbol{h}_1}$**

我们从 $l$ 对 $\boldsymbol{a}_2$ 的导数开始。如题解所述，这是一个已知结果：
$$\dfrac{\partial l}{\partial \boldsymbol{a}_2} = \operatorname{softmax}(\boldsymbol{a}_2) - \boldsymbol{y} \quad (\text{记作 } \boldsymbol{g}_2)$$
这个梯度表示了在输出层（softmax之前），预测值和真实值之间的误差。

现在，我们利用链式法则，将 $l$ 的变化 $dl$ 与 $\boldsymbol{a}_2$ 的变化 $d\boldsymbol{a}_2$ 联系起来：
$$dl = \operatorname{tr}\left( \left(\dfrac{\partial l}{\partial \boldsymbol{a}_2}\right)^T d\boldsymbol{a}_2 \right) = \operatorname{tr}(\boldsymbol{g}_2^T d\boldsymbol{a}_2)$$
接下来，我们看 $\boldsymbol{a}_2$ 是如何依赖于 $W_2$ 和 $\boldsymbol{h}_1$ 的。根据 $\boldsymbol{a}_2 = W_2 \boldsymbol{h}_1$，使用乘法法则求微分：
$$d\boldsymbol{a}_2 = (dW_2)\boldsymbol{h}_1 + W_2(d\boldsymbol{h}_1)$$
* 这里我们把 $W_2$ 和 $\boldsymbol{h}_1$ 都看作变量，它们微小的变化 $dW_2$ 和 $d\boldsymbol{h}_1$ 共同引起了 $d\boldsymbol{a}_2$。

把 $d\boldsymbol{a}_2$ 的表达式代入 $dl$：
$$dl = \operatorname{tr}\left( \boldsymbol{g}_2^T \left( (dW_2)\boldsymbol{h}_1 + W_2(d\boldsymbol{h}_1) \right) \right)$$
利用迹的线性性质 $\operatorname{tr}(A+B) = \operatorname{tr}(A) + \operatorname{tr}(B)$，我们把上式拆成两部分：
$$dl = \underbrace{\operatorname{tr}\left( \boldsymbol{g}_2^T (dW_2) \boldsymbol{h}_1 \right)}_{\text{用于求 } \dfrac{\partial l}{\partial W_2}}  + \underbrace{\operatorname{tr}\left( \boldsymbol{g}_2^T W_2 (d\boldsymbol{h}_1) \right)}_{\text{用于求 } \dfrac{\partial l}{\partial \boldsymbol{h}_1} \text{,也就是题解中的 } dl_2}$$

**1a. 求解 $\dfrac{\partial l}{\partial W_2}$**

我们看第一项：$\operatorname{tr}\left( \boldsymbol{g}_2^T (dW_2) \boldsymbol{h}_1 \right)$。
我们的目标是把它变成 $\operatorname{tr}(C^T dW_2)$ 的形式。这里需要用到迹的**循环不变性**：$\operatorname{tr}(ABC) = \operatorname{tr}(BCA) = \operatorname{tr}(CAB)$。
$$\operatorname{tr}\left( \underbrace{\boldsymbol{g}_2^T}_{A} \underbrace{(dW_2)}_{B} \underbrace{\boldsymbol{h}_1}_{C} \right) = \operatorname{tr}\left( \underbrace{\boldsymbol{h}_1}_{C} \underbrace{\boldsymbol{g}_2^T}_{A} \underbrace{(dW_2)}_{B} \right)$$
我们把它整理成 $\operatorname{tr}\left( (\boldsymbol{h}_1 \boldsymbol{g}_2^T) (dW_2) \right)$。这还不是我们想要的形式。我们的目标是 $\operatorname{tr}(C^T dW_2)$。
让我们再整理一下：
$$\operatorname{tr}\left( \boldsymbol{h}_1 \boldsymbol{g}_2^T dW_2 \right) = \operatorname{tr}\left( \left((\boldsymbol{g}_2 \boldsymbol{h}_1^T)^T\right) dW_2 \right)$$
因为 $(AB)^T = B^T A^T$，所以 $(\boldsymbol{g}_2 \boldsymbol{h}_1^T)^T = (\boldsymbol{h}_1^T)^T \boldsymbol{g}_2^T = \boldsymbol{h}_1 \boldsymbol{g}_2^T$。
所以，我们已经成功地将第一项整理成了 $\operatorname{tr}(C^T dW_2)$ 的形式，其中 $C = \boldsymbol{g}_2 \boldsymbol{h}_1^T$。
因此，我们得到：
$$\dfrac{\partial l}{\partial W_2} = \boldsymbol{g}_2 \boldsymbol{h}_1^T = (\operatorname{softmax}(\boldsymbol{a}_2) - \boldsymbol{y}) \boldsymbol{h}_1^T$$
这就是题解中的第一个结果。

**1b. 求解 $\dfrac{\partial l}{\partial \boldsymbol{h}_1}$**

我们看第二项：$dl_2 = \operatorname{tr}\left( \boldsymbol{g}_2^T W_2 d\boldsymbol{h}_1 \right)$。
目标是把它变成 $\operatorname{tr}(C^T d\boldsymbol{h}_1)$ 的形式。
$$\operatorname{tr}\left( (\boldsymbol{g}_2^T W_2) d\boldsymbol{h}_1 \right)$$
这已经是我们想要的形式了！只要令 $C^T = \boldsymbol{g}_2^T W_2$。
那么 $C = ( \boldsymbol{g}_2^T W_2 )^T = W_2^T (\boldsymbol{g}_2^T)^T = W_2^T \boldsymbol{g}_2$。
因此，我们得到：
$$\begin{align*}
\dfrac{\partial l}{\partial \boldsymbol{h}_1} &= W_2^T \boldsymbol{g}_2 \\
&= W_2^T (\operatorname{softmax}(\boldsymbol{a}_2) - \boldsymbol{y})
\end{align*}$$
这就是题解中的第二个中间结果。

---

### **第二步：求 $\dfrac{\partial l}{\partial W_1}$**

现在我们有了 $\dfrac{\partial l}{\partial \boldsymbol{h}_1}$，我们需要继续往前回溯到 $W_1$。
链条是这样的：$l \rightarrow \boldsymbol{h}_1 \rightarrow \boldsymbol{a}_1 \rightarrow W_1$。

**2a. 从 $\boldsymbol{h}_1$ 到 $\boldsymbol{a}_1$**

关系是 $\boldsymbol{h}_1 = \sigma(\boldsymbol{a}_1)$，这是一个逐元素（element-wise）的函数。
它的微分是：$d\boldsymbol{h}_1 = \sigma'(\boldsymbol{a}_1) \odot d\boldsymbol{a}_1$。
这里的 $\odot$ 表示**哈达玛积**（Hadamard product），即逐元素相乘。$\sigma'(\boldsymbol{a}_1)$ 是对 $\boldsymbol{a}_1$ 的每个元素求 sigmoid 的导数，结果还是一个向量。

我们从上一步得到的 $dl_2$ 出发：
$$dl_2 = \operatorname{tr}\left( \left(\dfrac{\partial l}{\partial \boldsymbol{h}_1}\right)^T d\boldsymbol{h}_1 \right)$$
代入 $d\boldsymbol{h}_1$ 的表达式：
$$dl_2 = \operatorname{tr}\left( \left(\dfrac{\partial l}{\partial \boldsymbol{h}_1}\right)^T (\sigma'(\boldsymbol{a}_1) \odot d\boldsymbol{a}_1) \right)$$
这里需要另一个非常有用的**迹技巧**：$\operatorname{tr}(A^T(B \odot C)) = \operatorname{tr}((A \odot B)^T C)$。
我们应用这个技巧：
$$dl_2 = \operatorname{tr}\left( \left( \dfrac{\partial l}{\partial \boldsymbol{h}_1} \odot \sigma'(\boldsymbol{a}_1) \right)^T d\boldsymbol{a}_1 \right)$$
现在，表达式又变成了 $\operatorname{tr}(C^T dX)$ 的形式，其中 $X = \boldsymbol{a}_1$ 且 $C = \dfrac{\partial l}{\partial \boldsymbol{h}_1} \odot \sigma'(\boldsymbol{a}_1)$。
所以我们得到：
$$\dfrac{\partial l}{\partial \boldsymbol{a}_1} = \dfrac{\partial l}{\partial \boldsymbol{h}_1} \odot \sigma'(\boldsymbol{a}_1) \quad (\text{记作 } \boldsymbol{g}_1)$$
这就是题解中的第三个中间结果。

**2b. 从 $\boldsymbol{a}_1$ 到 $W_1$**

关系是 $\boldsymbol{a}_1 = W_1 \boldsymbol{x}$。
它的微分是：$d\boldsymbol{a}_1 = (dW_1)\boldsymbol{x}$。（我们视输入 $\boldsymbol{x}$ 为常量，所以 $d\boldsymbol{x}=0$）。

我们再次使用链式法则的微分形式，这次是从 $l$ 到 $\boldsymbol{a}_1$：
$$dl_2 = \operatorname{tr}\left( \left(\dfrac{\partial l}{\partial \boldsymbol{a}_1}\right)^T d\boldsymbol{a}_1 \right) = \operatorname{tr}(\boldsymbol{g}_1^T d\boldsymbol{a}_1)$$
代入 $d\boldsymbol{a}_1$ 的表达式：
$$dl_2 = \operatorname{tr}\left( \boldsymbol{g}_1^T (dW_1) \boldsymbol{x} \right)$$
这和步骤 **1a** 的情况完全一样！我们再次使用迹的循环不变性 $\operatorname{tr}(ABC) = \operatorname{tr}(CAB)$：
$$\operatorname{tr}\left( \underbrace{\boldsymbol{g}_1^T}_{A} \underbrace{(dW_1)}_{B} \underbrace{\boldsymbol{x}}_{C} \right) = \operatorname{tr}\left( \underbrace{\boldsymbol{x}}_{C} \underbrace{\boldsymbol{g}_1^T}_{A} \underbrace{(dW_1)}_{B} \right) = \operatorname{tr}\left( (\boldsymbol{x} \boldsymbol{g}_1^T) dW_1 \right)$$
为了匹配 $\operatorname{tr}(C^T dW_1)$ 的形式，我们有 $C^T = \boldsymbol{x} \boldsymbol{g}_1^T$。
因此 $C = (\boldsymbol{x} \boldsymbol{g}_1^T)^T = (\boldsymbol{g}_1^T)^T \boldsymbol{x}^T = \boldsymbol{g}_1 \boldsymbol{x}^T$。
最终我们得到：
$$\dfrac{\partial l}{\partial W_1} = \boldsymbol{g}_1 \boldsymbol{x}^T = \left(\dfrac{\partial l}{\partial \boldsymbol{a}_1}\right) \boldsymbol{x}^T$$
这就是题解中的最终结果。

### 总结

整个过程就是反复应用两个核心步骤：
1.  写出当前变量的微分表达式（如 $d\boldsymbol{a}_2 = dW_2 \boldsymbol{h}_1 + W_2 d\boldsymbol{h}_1$）。
2.  代入到 $dl = \operatorname{tr}((\text{上一层梯度})^T d(\text{上一层变量}))$ 的公式中。
3.  使用各种**迹技巧**，将表达式整理成 $dl = \operatorname{tr}(C^T dX)$ 的形式，从而直接读出梯度 $\dfrac{\partial l}{\partial X} = C$。

通过这种方式，我们可以一步步地、严谨地、机械地从损失函数 $l$ 开始，反向推导出每一层参数的梯度，而无需处理复杂的索引和求和。
