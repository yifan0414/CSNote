---
created: 2025-04-08 19:43
tags:
---

# 高斯朴素贝叶斯分类器的训练过程

要训练一个高斯朴素贝叶斯分类器，获得每个类别 $C$ 下各个特征的均值和方差，我们需要使用**最大似然估计**（Maximum Likelihood Estimation, MLE）来估计这些参数。具体来说，我们通过训练集中的数据来估计每个类别 $C$ 下各个特征 $x_i$ 的均值（$\mu_C$）和方差（$\sigma_C^2$）。

## 步骤

### 1. 获取训练数据
训练集通常是由一组样本 $x_1, x_2, \dots, x_n$ 组成，每个样本包含多个特征 $x_1, x_2, \dots, x_d$ 和一个标签 $y$（类别 $C$）。每个数据点可以表示为 $(x, y)$，其中：
- $x = (x_1, x_2, \dots, x_d)$ 是特征向量，包含 $d$ 个特征；
- $y$ 是类别标签，表示样本所属的类别。

### 2. 计算每个类别 $C$ 的均值和方差
对于每个类别 $C$，我们需要计算其特征的**均值**和**方差**。对于类别 $C$ 下的每个特征 $x_i$：

- **均值（$\mu_C$）**：类别 $C$ 下特征 $x_i$ 的均值是训练集中文本属于类别 $C$ 的所有样本中该特征的平均值。具体计算公式如下：

  $$
  \mu_C = \frac{1}{N_C} \sum_{i=1}^{N_C} x_i^{(C)}
$$
  
  其中：
  - $N_C$ 是属于类别 $C$ 的样本数；
  - $x_i^{(C)}$ 是类别 $C$ 下第 $i$ 个特征的值。

- **方差（$\sigma_C^2$）**：类别 $C$ 下特征 $x_i$ 的方差是该特征在类别 $C$ 下所有样本值的方差，计算公式为：

  $$
  \sigma_C^2 = \frac{1}{N_C} \sum_{i=1}^{N_C} (x_i^{(C)} - \mu_C)^2
$$

  其中：
  - $x_i^{(C)}$ 是类别 $C$ 下第 $i$ 个特征的值；
  - $\mu_C$ 是类别 $C$ 下该特征的均值；
  - $N_C$ 是属于类别 $C$ 的样本数。

### 3. 最大似然估计
对于给定类别 $C$，我们希望找到最适合训练数据的**高斯分布**参数。由于我们假设每个特征 $x_i$ 在类别 $C$ 下服从高斯分布，因此，我们通过最大化似然函数来估计均值和方差。

- **似然函数**：高斯分布的似然函数是训练集中每个样本在给定类别 $C$ 下的概率密度函数的乘积：

  $$
  P(x_1, x_2, \dots, x_n | C) = \prod_{i=1}^n P(x_i | C)
$$

  由于我们假设每个特征在类别 $C$ 下是独立的，因此总的似然函数是各个特征的似然函数的乘积。

- **最大化似然**：为了最大化似然函数，我们求解均值和方差的公式。这相当于对训练集中的每个特征计算其均值和方差，得出的结果就是最大化似然的参数。

### 4. 训练过程
- **步骤1**：遍历所有训练样本，根据其标签 $y$ 将其分配到相应的类别 $C$。
- **步骤2**：对每个类别 $C$，计算该类别下每个特征的均值和方差。
- **步骤3**：重复步骤1和步骤2直到遍历完所有类别和特征。

## 例子：
假设我们有一个简单的二分类问题，类别 $C_1$ 和 $C_2$，每个样本有两个特征（例如身高和体重）。我们有以下数据集：

| 样本编号 | 身高（特征1） | 体重（特征2） | 类别    |
| ---- | ------- | ------- | ----- |
| 1    | 170     | 65      | $C_1$ |
| 2    | 180     | 75      | $C_1$ |
| 3    | 160     | 55      | $C_2$ |
| 4    | 165     | 60      | $C_2$ |

1. **计算均值**：
   - 对于类别 $C_1$，计算每个特征（身高和体重）的均值：
     $$
     \mu_{C_1, \text{身高}} = \frac{170 + 180}{2} = 175, \quad \mu_{C_1, \text{体重}} = \frac{65 + 75}{2} = 70
$$
   - 对于类别 $C_2$，计算每个特征（身高和体重）的均值：
     $$
     \mu_{C_2, \text{身高}} = \frac{160 + 165}{2} = 162.5, \quad \mu_{C_2, \text{体重}} = \frac{55 + 60}{2} = 57.5
$$

2. **计算方差**：
   - 对于类别 $C_1$，计算每个特征的方差：
$$
	\begin{aligned}
     \sigma_{C_1, \text{身高}}^2 &= \frac{(170-175)^2 + (180-175)^2}{2} = 25,\\ \quad \sigma_{C_1, \text{体重}}^2 &= \frac{(65-70)^2 + (75-70)^2}{2} = 25
\end{aligned}
$$
   - 对于类别 $C_2$，计算每个特征的方差：
$$
\begin{aligned}
     \sigma_{C_2, \text{身高}}^2 &= \frac{(160-162.5)^2 + (165-162.5)^2}{2} = 6.25, \\\quad \sigma_{C_2, \text{体重}}^2 &= \frac{(55-57.5)^2 + (60-57.5)^2}{2} = 6.25
\end{aligned}
$$

3. **重复训练过程**，直到我们计算出所有类别的均值和方差。

## 总结：
通过上述步骤，我们能够通过训练数据来估计每个类别 $C$ 下每个特征的**均值**和**方差**，这些参数在高斯朴素贝叶斯分类器中非常重要，后续可以用它们来计算新样本属于各个类别的概率。


好的，让我们继续使用上面提到的身高和体重的例子，通过最大似然估计来解释如何估计最优的均值和方差。

### 问题回顾

假设我们有以下数据集，其中每个样本有两个特征：身高和体重。类别 $C_1$ 和 $C_2$ 具有如下数据：

| 样本编号 | 身高（特征1） | 体重（特征2） | 类别 |
|----------|---------------|---------------|------|
| 1        | 170           | 65            | $C_1$ |
| 2        | 180           | 75            | $C_1$ |
| 3        | 160           | 55            | $C_2$ |
| 4        | 165           | 60            | $C_2$ |

我们希望通过最大似然估计来计算每个特征（身高和体重）的**均值**和**方差**。首先，我们会根据最大似然估计的步骤来计算这些参数。

# 二维高斯分布朴素 bayes 分类器
对于包含两个特征的情况（如图中的 **SP Defense** 和 **Defense**），我们使用**二维高斯分布**来表示它们的联合概率密度函数（PDF）。在这种情况下，我们的目标是通过**最大似然估计**来找到最佳的参数，包括每个特征的**均值**和它们之间的**协方差**。

### 1. **二维高斯分布的概率密度函数**

假设有 $n$ 个样本，每个样本有两个特征 $x_1$（SP Defense）和 $x_2$（Defense）。每个样本都可以看作是从一个二维高斯分布中采样得到的。二维高斯分布的概率密度函数为：

$$
f_{\mu, \Sigma}(x) = \frac{1}{(2\pi)^{D/2} |\Sigma|^{1/2}} \exp \left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right)
$$

其中：
- $D$ 是特征的维度，在这里 $D = 2$；
- $x = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}$ 是样本数据点；
- $\mu = \begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix}$ 是均值向量，包含两个特征的均值；
- $\Sigma$ 是协方差矩阵，表示特征的方差和它们之间的协方差；
- $|\Sigma|$ 是协方差矩阵 $\Sigma$ 的行列式。

### 2. **最大似然估计**

最大似然估计的目标是根据观察到的数据来估计最好的参数（即均值和协方差矩阵）。给定 $n$ 个样本 $\{ x^{(1)}, x^{(2)}, \dots, x^{(n)} \}$，我们希望找到 $\mu$ 和 $\Sigma$，使得这些参数最大化似然函数。

#### 似然函数

假设我们有 $n$ 个独立同分布（i.i.d.）的样本，似然函数 $L(\mu, \Sigma)$ 是所有样本在给定参数下的联合概率：

$$
L(\mu, \Sigma) = \prod_{i=1}^{n} f_{\mu, \Sigma}(x^{(i)})
$$

将二维高斯分布的PDF代入得到：

$$
L(\mu, \Sigma) = \prod_{i=1}^{n} \frac{1}{(2\pi)^{D/2} |\Sigma|^{1/2}} \exp \left( -\frac{1}{2} (x^{(i)} - \mu)^T \Sigma^{-1} (x^{(i)} - \mu) \right)
$$

#### 对数似然函数

为了简化计算，通常我们使用对数似然函数（log-likelihood）：

$$
\log L(\mu, \Sigma) = \sum_{i=1}^{n} \log \left( \frac{1}{(2\pi)^{D/2} |\Sigma|^{1/2}} \exp \left( -\frac{1}{2} (x^{(i)} - \mu)^T \Sigma^{-1} (x^{(i)} - \mu) \right) \right)
$$

对数似然函数可以进一步简化为：

$$
\log L(\mu, \Sigma) = -\frac{n}{2} \log (2 \pi) - \frac{n}{2} \log |\Sigma| - \frac{1}{2} \sum_{i=1}^{n} (x^{(i)} - \mu)^T \Sigma^{-1} (x^{(i)} - \mu)
$$

### 3. **最大化对数似然函数**

为了估计 $\mu$ 和 $\Sigma$，我们需要对对数似然函数分别对 $\mu$ 和 $\Sigma$ 求偏导数，并使其等于零。

#### （1）对 $\mu$ 求导数

对 $\mu$ 求偏导数：

$$
\frac{\partial}{\partial \mu} \log L(\mu, \Sigma) = \sum_{i=1}^{n} \Sigma^{-1} (x^{(i)} - \mu)
$$

设其为零，解得：

$$
\sum_{i=1}^{n} (x^{(i)} - \mu) = 0
$$

因此，**均值的最大似然估计**是样本均值：

$$
\hat{\mu} = \frac{1}{n} \sum_{i=1}^{n} x^{(i)}
$$

#### （2）对 $\Sigma$ 求导数
对协方差矩阵 $\Sigma$ 求偏导数：

$$
\frac{\partial}{\partial \Sigma} \log L(\mu, \Sigma) = \frac{1}{2} \Sigma^{-1} - \frac{1}{2} \Sigma^{-1} \sum_{i=1}^{n} (x^{(i)} - \mu)(x^{(i)} - \mu)^T \Sigma^{-1}
$$

设其为零，解得：

$$
\hat{\Sigma} = \frac{1}{n} \sum_{i=1}^{n} (x^{(i)} - \hat{\mu})(x^{(i)} - \hat{\mu})^T
$$

### 4. **结果**

通过最大似然估计，我们得到了以下的估计值：
- **均值的最大似然估计**：

$$
\hat{\mu} = \frac{1}{n} \sum_{i=1}^{n} x^{(i)}
$$

- **协方差矩阵的最大似然估计**：

$$
\hat{\Sigma} = \frac{1}{n} \sum_{i=1}^{n} (x^{(i)} - \hat{\mu})(x^{(i)} - \hat{\mu})^T
$$

### 总结：

最大似然估计通过最大化对数似然函数来估计参数。对于二维高斯分布，我们使用样本的均值和样本的协方差矩阵来分别估计 **均值向量** 和 **协方差矩阵**，这将为我们提供每个特征联合分布的最优参数。在实际应用中，通常我们会使用这些参数来计算新数据点在该分布下的概率，从而进行分类或其他分析。