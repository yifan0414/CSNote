---
created: 2025-04-04 11:29
tags:
---
机器学习从解决问题的方式上大致分为频率派和贝叶斯派。 

频率派又可以称为统计机器学习，svm，dnn，pca等算法都属于这一类，李航有本书写的算法，大致属于这一派。 

贝叶斯派也可以叫概率图模型，有高斯混合模型，条件随机场，玻尔兹曼机，隐马尔科夫模型都属于这一类算法。 coursera吴恩达，李宏毅，讲解的机器学习主要是从直觉上去理解，数学公式推导较少，讲解的以统计学习方法为主，可以作为初始者的学习。

哔哩哩哔的白板推导，徐义达，讲解的主要是概率图模型，需要较强的数学推导，对于提高非常有用。虽然概率图模型现在已经不常用了，但是里面的很多解题方法思路，都会被用到统计学习中，比如变分推断，importance sampling，EM等。比较出名的花书前两部分讲解的就是统计机器学习方法，第三部分就是概率图模型




> [!NOTE]- 概率图模型不常用的解释
> 概率图模型（Probabilistic Graphical Models，PGM）在过去的机器学习研究和应用中确实非常重要，但近年来，它们的使用相对减少，主要是由于以下几个原因：
> 
> ### 1. **深度学习的崛起**
> 随着**深度学习**（Deep Learning）技术的快速发展，尤其是在计算能力的提升和大数据的支持下，深度神经网络（DNN）在许多任务中取得了令人瞩目的成果。深度学习方法（如卷积神经网络（CNN）、循环神经网络（RNN）、生成对抗网络（GAN）等）在图像、语音、自然语言处理等领域表现出色，相比之下，概率图模型的应用逐渐减少。
> 
> 深度学习模型可以自动从大量数据中学习复杂的特征，而不需要手动设计复杂的概率模型。这种“端到端”的学习方式非常适合处理高维数据和复杂模式，因此在许多任务中逐渐替代了传统的概率图模型。
> 
> ### 2. **计算和推理的复杂性**
> 概率图模型，尤其是**大规模**的模型（如**隐马尔科夫模型（HMM）**和**条件随机场（CRF）**等），在推理和参数估计上通常非常复杂，尤其是在数据维度很高或者模型结构较大时。推理过程可能需要使用复杂的算法，如**变分推断**（Variational Inference）或**马尔可夫链蒙特卡洛（MCMC）**，这些方法计算开销较大，且有时难以实现高效的推理。
> 
> 虽然存在一些优化技术来简化计算，但与深度学习的“梯度下降”方法相比，概率图模型的计算复杂度通常更高，导致它们在处理大规模数据时的实用性受到限制。
> 
> ### 3. **数据和模型的匹配问题**
> 概率图模型强调从先验概率和条件概率的角度建模问题，通常需要显式地定义数据的分布和结构。这种建模方式在一些问题中很有效，尤其是当数据关系和概率分布已知或可以清晰地定义时（例如，传统的语音识别、自然语言处理中的某些任务）。
> 
> 然而，在许多实际问题中，数据的关系和分布并不完全明确，尤其是在大规模无标签数据的情况下，使用传统的概率图模型可能难以获得理想的结果。而深度学习模型可以通过大量的训练数据学习数据的分布和结构，因此在很多情况下，深度学习模型表现得更好。
> 
> ### 4. **模型复杂性与解释性**
> 尽管概率图模型提供了明确的概率推理框架，并且在某些领域（如统计建模和不确定性推理）具有很好的解释性，但这些模型通常结构复杂，参数众多，且对于大规模复杂数据的适应性差。而深度学习虽然通常被认为是“黑箱”，但是其高度灵活的结构和强大的表达能力使得它在许多应用场景中成为了首选方法。
> 
> ### 5. **现代方法的折中**
> 实际上，现代机器学习方法并不是完全抛弃概率图模型，而是通过**混合方法**将两者结合起来。例如，近年来的一些研究尝试结合**深度学习**和**概率图模型**，例如在生成模型（如生成对抗网络（GAN）和变分自编码器（VAE））中，深度神经网络和概率推理方法结合得较好。这些混合方法利用了深度学习的强大表示能力，同时保持了概率图模型的结构和不确定性建模优势。
> 
> ### 总结
> 概率图模型现在不常用了，主要是因为深度学习的崛起，计算推理复杂性的问题，以及深度学习在处理大规模数据和复杂任务中的优势。不过，概率图模型中的很多思想（如**变分推断**、**EM 算法**、**重要性采样**等）仍然在现代统计学习中有着广泛应用，并且随着深度学习的发展，很多研究者开始尝试将两者结合，开发出新的方法。