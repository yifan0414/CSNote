---
created: 2025-04-19 02:11
tags:
---
```python
def nll(input, target):
    # input: 通常是模型输出的对数概率 (log probabilities)，形状如 (batch_size, num_classes)
    # target: 包含真实类别标签的张量，形状如 (batch_size,)，每个值是 0 到 num_classes-1 的整数

    # 1. input[range(target.shape[0]), target]
    #    - target.shape[0] 获取批次大小 (batch_size)
    #    - range(target.shape[0]) 生成一个从 0 到 batch_size-1 的序列，代表行索引
    #    - target 本身提供了列索引（即每个样本对应的真实类别）
    #    - 这个索引操作会从 input 中为批次里的 *每个* 样本，精确地提取出其 *真实类别* 对应的那个对数概率值。
    #    - 例如：如果 input[i] 是第 i 个样本的对数概率向量，target[i] 是第 i 个样本的真实类别 k，
    #      那么这个操作会取出 input[i, k] 的值。

    # 2. .mean()
    #    - 计算上一步提取出的所有对数概率值的平均数。

    # 3. - ...
    #    - 对计算出的平均值取负。

    return -input[range(target.shape[0]), target].mean()

# 将 nll 函数赋值给变量 loss_func
loss_func = nll
```

好的，这个 `nll` 函数计算的是**平均负对数似然损失 (Average Negative Log Likelihood Loss)**。

其数学公式可以表示如下：

假设：

* $N$ 是批次大小 (batch size)，即 `target.shape[0]`。
* $C$ 是类别的总数。
* $L$ 是模型的输出矩阵，其元素 $L_{ij}$ 代表模型预测第 $i$ 个样本属于第 $j$ 个类别的**对数概率** (log probability)。 $L$ 的维度是 $N \times C$ (对应代码中的 `input`)。
* $y$ 是一个包含真实类别标签的向量，其元素 $y_i$ 代表第 $i$ 个样本的真实类别索引 ($0 \le y_i < C$)。 $y$ 的长度是 $N$ (对应代码中的 `target`)。

那么，这个 `nll` 函数计算的损失 $\mathcal{L}$ 为：

$$\mathcal{L}_{\text{NLL}}(L, y) = -\frac{1}{N} \sum_{i=0}^{N-1} L_{i, y_i}$$

**公式解释：**

1.  $L_{i, y_i}$ : 对于第 $i$ 个样本，我们根据其真实类别标签 $y_i$ 从模型输出的对数概率矩阵 $L$ 中选取对应的那个值。这表示模型赋予**真实类别**的对数概率。
2.  $\sum_{i=0}^{N-1} L_{i, y_i}$ : 将批次中所有样本的真实类别对应的对数概率相加。
3.  $\frac{1}{N} \sum_{i=0}^{N-1} L_{i, y_i}$ : 计算这些对数概率的平均值。
4.  $-\frac{1}{N} \sum_{i=0}^{N-1} L_{i, y_i}$ : 对平均值取负号。

这个损失函数的目标就是通过训练模型来最小化这个 $\mathcal{L}$ 值，也就等同于最大化模型赋予正确类别的（对数）概率。